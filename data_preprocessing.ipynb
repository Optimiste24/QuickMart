{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b21e8f-e27d-4cc0-9c9c-ecd1a937e6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d5c816-ce74-4b11-8038-4d1e453382e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03facff-45f8-458c-b4e2-1f87c0685353",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Prophet' object has no attribute 'stan_backend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m     79\u001b[0m     df \u001b[38;5;241m=\u001b[39m prepare_data(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarketing\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 80\u001b[0m     model, forecast, mape \u001b[38;5;241m=\u001b[39m train_and_validate(df)\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ MAPE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmape\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (objectif : < 15%)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     plot_forecast(model, forecast)\n",
      "Cell \u001b[1;32mIn[2], line 59\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     57\u001b[0m test \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m split_date]\n\u001b[0;32m     58\u001b[0m train_prophet \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m---> 59\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model()\n\u001b[0;32m     60\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_prophet)\n\u001b[0;32m     61\u001b[0m future \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmake_future_dataframe(periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test))\n",
      "Cell \u001b[1;32mIn[2], line 46\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m():\n\u001b[1;32m---> 46\u001b[0m     model \u001b[38;5;241m=\u001b[39m Prophet(weekly_seasonality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, yearly_seasonality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m                     changepoint_prior_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, seasonality_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultiplicative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     48\u001b[0m     model\u001b[38;5;241m.\u001b[39madd_regressor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m     model\u001b[38;5;241m.\u001b[39madd_regressor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpromo_active\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\prophet\\forecaster.py:155\u001b[0m, in \u001b[0;36mProphet.__init__\u001b[1;34m(self, growth, changepoints, n_changepoints, changepoint_range, yearly_seasonality, weekly_seasonality, daily_seasonality, holidays, seasonality_mode, seasonality_prior_scale, holidays_prior_scale, changepoint_prior_scale, mcmc_samples, interval_width, uncertainty_samples, stan_backend, scaling, holidays_mode)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_inputs()\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_stan_backend(stan_backend)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\prophet\\forecaster.py:168\u001b[0m, in \u001b[0;36mProphet._load_stan_backend\u001b[1;34m(self, stan_backend)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend \u001b[38;5;241m=\u001b[39m StanBackendEnum\u001b[38;5;241m.\u001b[39mget_backend_class(stan_backend)()\n\u001b[1;32m--> 168\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded stan backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39mget_type())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Prophet' object has no attribute 'stan_backend'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Chargement des donn√©es\n",
    "def load_data():\n",
    "    data_dir = Path('data')\n",
    "    try:\n",
    "        df_sales = pd.read_csv(data_dir/'ventes_enhanced.csv', parse_dates=['Date'])\n",
    "        df_weather = pd.read_csv(data_dir/'meteo_locale.csv', parse_dates=['Date'])\n",
    "        df_products = pd.read_csv(data_dir/'produits.csv')\n",
    "        df_staff = pd.read_csv(data_dir/'planning_equipes.csv', parse_dates=['Date'])\n",
    "        df_marketing = pd.read_csv(data_dir/'campagnes_marketing.csv', encoding='latin1', parse_dates=['Date_d√©but', 'Date_fin'])\n",
    "        return {\n",
    "            'sales': df_sales,\n",
    "            'weather': df_weather,\n",
    "            'products': df_products,\n",
    "            'staff': df_staff,\n",
    "            'marketing': df_marketing\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du chargement des donn√©es: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Pr√©paration des donn√©es\n",
    "def prepare_data(df_sales, df_weather, df_marketing):\n",
    "    df_daily = df_sales.groupby('Date').agg({'CA': 'sum', 'Magasin': 'nunique'}).reset_index()\n",
    "    df_weather_daily = df_weather.groupby('Date')['Temp√©rature'].mean().reset_index()\n",
    "    df_weather_daily.rename(columns={'Temp√©rature': 'temperature'}, inplace=True)\n",
    "    df_merged = pd.merge(df_daily, df_weather_daily, on='Date')\n",
    "    df_merged['promo_active'] = df_merged['Date'].apply(\n",
    "        lambda d: any((d >= row['Date_d√©but']) & (d <= row['Date_fin']) for _, row in df_marketing.iterrows())\n",
    "    ).astype(int)\n",
    "    return df_merged\n",
    "\n",
    "# Cr√©ation du mod√®le Prophet\n",
    "def create_model():\n",
    "    model = Prophet(weekly_seasonality=True, yearly_seasonality=False,\n",
    "                    changepoint_prior_scale=0.3, seasonality_mode='multiplicative')\n",
    "    model.add_regressor('temperature')\n",
    "    model.add_regressor('promo_active')\n",
    "    model.add_country_holidays(country_name='FR')\n",
    "    return model\n",
    "\n",
    "# Entra√Ænement + validation + MAPE\n",
    "def train_and_validate(df):\n",
    "    split_date = df['Date'].quantile(0.8)\n",
    "    train = df[df['Date'] <= split_date]\n",
    "    test = df[df['Date'] > split_date]\n",
    "    train_prophet = train.rename(columns={'Date': 'ds', 'CA': 'y'})\n",
    "    model = create_model()\n",
    "    model.fit(train_prophet)\n",
    "    future = model.make_future_dataframe(periods=len(test))\n",
    "    future = future.merge(df[['Date', 'temperature', 'promo_active']], left_on='ds', right_on='Date', how='left')\n",
    "    forecast = model.predict(future)\n",
    "    from sklearn.metrics import mean_absolute_percentage_error\n",
    "    mape = mean_absolute_percentage_error(test['CA'], forecast.tail(len(test))['yhat'])\n",
    "    return model, forecast, mape\n",
    "\n",
    "# Affichage\n",
    "def plot_forecast(model, forecast):\n",
    "    fig1 = model.plot(forecast)\n",
    "    plt.title(\"Pr√©visions de chiffre d'affaires\")\n",
    "    plt.show()\n",
    "    fig2 = model.plot_components(forecast)\n",
    "    plt.show()\n",
    "\n",
    "# Ex√©cution compl√®te\n",
    "data = load_data()\n",
    "if data:\n",
    "    df = prepare_data(data['sales'], data['weather'], data['marketing'])\n",
    "    model, forecast, mape = train_and_validate(df)\n",
    "    print(f\"‚úÖ MAPE: {mape:.1%} (objectif : < 15%)\")\n",
    "    plot_forecast(model, forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170001d4-2f06-4718-9826-aadeb37e3fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Local\\Temp\\ipykernel_17760\\803535250.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Local\\Temp\\ipykernel_17760\\803535250.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üöÄ D√©marrage du pipeline de pr√©vision\n",
      "==================================================\n",
      "\n",
      "üîç √âtape 1/5 - Chargement des donn√©es...\n",
      "\n",
      "üßπ √âtape 2/5 - Nettoyage et fusion des donn√©es...\n",
      "üìä Donn√©es apr√®s nettoyage: (455, 7)\n",
      "\n",
      "‚öôÔ∏è √âtape 3/5 - Cr√©ation des features...\n",
      "‚ú® Features ajout√©es: 21 au total\n",
      "\n",
      "üìä √âtape 4/5 - Pr√©paration pour Prophet...\n",
      "üìÖ P√©riode couverte: NaT au NaT\n",
      "\n",
      "ü§ñ √âtape 5/5 - Mod√©lisation Prophet...\n",
      "‚ùå √âchec de l'entra√Ænement: Donn√©es d'entr√©e invalides\n",
      "\n",
      "‚ùå Le pipeline a rencontr√© des probl√®mes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.serialize import model_to_json\n",
    "import holidays\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration initiale\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Chargement des donn√©es - Version am√©lior√©e\n",
    "def load_data():\n",
    "    \"\"\"Charge tous les fichiers CSV n√©cessaires avec gestion des erreurs\"\"\"\n",
    "    data_dir = Path('data')\n",
    "    try:\n",
    "        df_sales = pd.read_csv(data_dir/'ventes_enhanced.csv', parse_dates=['Date'])\n",
    "        df_weather = pd.read_csv(data_dir/'meteo_locale.csv', parse_dates=['Date'])\n",
    "        df_products = pd.read_csv(data_dir/'produits.csv')\n",
    "        df_staff = pd.read_csv(data_dir/'planning_equipes.csv', parse_dates=['Date'])\n",
    "        \n",
    "        return {\n",
    "            'sales': df_sales,\n",
    "            'weather': df_weather,\n",
    "            'products': df_products,\n",
    "            'staff': df_staff\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du chargement des donn√©es: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 2. Nettoyage des donn√©es - Version robuste\n",
    "def clean_data(df_sales, df_weather):\n",
    "    \"\"\"Nettoie et fusionne les donn√©es avec v√©rifications\"\"\"\n",
    "    try:\n",
    "        # V√©rification des entr√©es\n",
    "        if df_sales.empty or df_weather.empty:\n",
    "            raise ValueError(\"DataFrames d'entr√©e vides\")\n",
    "            \n",
    "        # Gestion des outliers avec seuil dynamique\n",
    "        q_low = df_sales['CA'].quantile(0.005)\n",
    "        q_high = df_sales['CA'].quantile(0.995)\n",
    "        df_sales = df_sales[(df_sales['CA'] > q_low) & (df_sales['CA'] < q_high)]\n",
    "        \n",
    "        # D√©tection des jours ferm√©s\n",
    "        daily_sales = df_sales.groupby('Date')['CA'].sum()\n",
    "        closed_days = daily_sales[daily_sales == 0].index\n",
    "        df_sales = df_sales[~df_sales['Date'].isin(closed_days)]\n",
    "        \n",
    "        # Fusion avec v√©rification des cl√©s\n",
    "        df_merged = pd.merge(\n",
    "            df_sales.groupby(['Date', 'Magasin'])['CA'].sum().reset_index(),\n",
    "            df_weather,\n",
    "            left_on=['Date', 'Magasin'],\n",
    "            right_on=['Date', 'Ville'],\n",
    "            how='left'\n",
    "        ).dropna(subset=['CA'])\n",
    "        \n",
    "        # Jours f√©ri√©s avec gestion des ann√©es\n",
    "        years = df_merged['Date'].dt.year.unique()\n",
    "        fr_holidays = holidays.France(years=years)\n",
    "        df_merged['is_holiday'] = df_merged['Date'].apply(lambda x: x in fr_holidays)\n",
    "        \n",
    "        return df_merged\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du nettoyage: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 3. Feature Engineering - Optimis√©\n",
    "def create_features(df):\n",
    "    \"\"\"Cr√©e des variables suppl√©mentaires avec gestion des erreurs\"\"\"\n",
    "    try:\n",
    "        # V√©rification des colonnes n√©cessaires\n",
    "        if 'Date' not in df.columns or 'CA' not in df.columns:\n",
    "            raise ValueError(\"Colonnes manquantes\")\n",
    "            \n",
    "        # Variables temporelles\n",
    "        df['day_of_week'] = df['Date'].dt.dayofweek\n",
    "        df['month'] = df['Date'].dt.month\n",
    "        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "        \n",
    "        # Features temporelles avanc√©es\n",
    "        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week']/7)\n",
    "        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week']/7)\n",
    "        \n",
    "        # Lag features avec fen√™tre glissante\n",
    "        for lag in [1, 7, 14]:\n",
    "            df[f'CA_lag{lag}'] = df.groupby('Magasin')['CA'].shift(lag)\n",
    "            \n",
    "        # Rolling statistics\n",
    "        for window in [7, 14, 28]:\n",
    "            df[f'CA_rolling{window}_mean'] = df.groupby('Magasin')['CA'].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).mean()\n",
    "            )\n",
    "            df[f'CA_rolling{window}_std'] = df.groupby('Magasin')['CA'].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).std()\n",
    "            )\n",
    "        \n",
    "        return df.dropna().reset_index(drop=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur dans le feature engineering: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 4. Pr√©paration pour Prophet - Adaptatif\n",
    "def prepare_for_prophet(df, magasin_id=None):\n",
    "    \"\"\"Pr√©pare les donn√©es pour Prophet avec s√©lection de magasin\"\"\"\n",
    "    try:\n",
    "        if magasin_id:\n",
    "            df = df[df['Magasin'] == magasin_id].copy()\n",
    "            \n",
    "        # S√©lection des colonnes pertinentes\n",
    "        keep_cols = ['Date', 'CA', 'Temp√©rature', 'is_weekend', 'is_holiday']\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        keep_cols += [col for col in numeric_cols if col not in keep_cols and 'CA_' in col]\n",
    "        \n",
    "        prophet_df = df[keep_cols].rename(columns={'Date': 'ds', 'CA': 'y'})\n",
    "        \n",
    "        # Normalisation des noms de colonnes\n",
    "        prophet_df.columns = [col.lower().replace('√©', 'e') for col in prophet_df.columns]\n",
    "        \n",
    "        return prophet_df.dropna()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur de pr√©paration Prophet: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 5. Mod√©lisation Prophet - Version professionnelle\n",
    "class ProphetModel:\n",
    "    def __init__(self, params=None):\n",
    "        self.params = params or {\n",
    "            'daily_seasonality': False,\n",
    "            'weekly_seasonality': True,\n",
    "            'yearly_seasonality': True,\n",
    "            'changepoint_prior_scale': 0.05,\n",
    "            'seasonality_mode': 'multiplicative'\n",
    "        }\n",
    "        self.model = None\n",
    "        \n",
    "    def train(self, df):\n",
    "        \"\"\"Entra√Æne le mod√®le avec gestion compl√®te des erreurs\"\"\"\n",
    "        try:\n",
    "            # Validation des donn√©es\n",
    "            if df is None or df.empty:\n",
    "                raise ValueError(\"Donn√©es d'entr√©e invalides\")\n",
    "                \n",
    "            required_cols = {'ds', 'y'}\n",
    "            if not required_cols.issubset(df.columns):\n",
    "                raise ValueError(f\"Colonnes requises manquantes: {required_cols - set(df.columns)}\")\n",
    "            \n",
    "            # Initialisation du mod√®le\n",
    "            self.model = Prophet(**self.params)\n",
    "            \n",
    "            # Ajout des regresseurs dynamiques\n",
    "            regressors = [col for col in df.columns if col not in required_cols]\n",
    "            for reg in regressors:\n",
    "                try:\n",
    "                    self.model.add_regressor(reg)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Regresseur {reg} ignor√©: {str(e)}\")\n",
    "            \n",
    "            # Entra√Ænement\n",
    "            self.model.fit(df)\n",
    "            print(\"‚úÖ Mod√®le entra√Æn√© avec succ√®s\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå √âchec de l'entra√Ænement: {str(e)}\")\n",
    "            self.model = None\n",
    "            return False\n",
    "    \n",
    "    def validate(self, df, initial='60 days', period='15 days', horizon='30 days', mape_threshold=0.15):\n",
    "        \"\"\"Validation crois√©e\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"‚ùå Mod√®le non entra√Æn√©\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            df_cv = cross_validation(\n",
    "                self.model,\n",
    "                initial=initial,\n",
    "                period=period,\n",
    "                horizon=horizon\n",
    "            )\n",
    "            \n",
    "            metrics = performance_metrics(df_cv)\n",
    "            mape = metrics['mape'].mean()\n",
    "            print(f\"üìä Performance MAPE: {mape:.2%}\")\n",
    "            \n",
    "            return mape <= mape_threshold\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå √âchec de validation: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def save_model(self, path='models/prophet_model.json'):\n",
    "        \"\"\"Sauvegarde le mod√®le\"\"\"\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "            with open(path, 'w') as f:\n",
    "                f.write(model_to_json(self.model))\n",
    "            print(f\"‚úÖ Mod√®le sauvegard√©: {path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå √âchec de sauvegarde: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "# Pipeline complet avec journalisation\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üöÄ D√©marrage du pipeline de pr√©vision\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # 1. Chargement des donn√©es\n",
    "    print(\"üîç √âtape 1/5 - Chargement des donn√©es...\")\n",
    "    data = load_data()\n",
    "    if data is None:\n",
    "        return\n",
    "\n",
    "    # 2. Nettoyage et fusion\n",
    "    print(\"\\nüßπ √âtape 2/5 - Nettoyage et fusion des donn√©es...\")\n",
    "    df_clean = clean_data(data['sales'], data['weather'])\n",
    "    if df_clean is None:\n",
    "        return\n",
    "    print(f\"üìä Donn√©es apr√®s nettoyage: {df_clean.shape}\")\n",
    "\n",
    "    # 3. Feature engineering\n",
    "    print(\"\\n‚öôÔ∏è √âtape 3/5 - Cr√©ation des features...\")\n",
    "    df_features = create_features(df_clean)\n",
    "    if df_features is None:\n",
    "        return\n",
    "    print(f\"‚ú® Features ajout√©es: {len(df_features.columns)} au total\")\n",
    "\n",
    "    # 4. Pr√©paration Prophet\n",
    "    print(\"\\nüìä √âtape 4/5 - Pr√©paration pour Prophet...\")\n",
    "    prophet_data = prepare_for_prophet(df_features, magasin_id='Magasin_1')\n",
    "    if prophet_data is None:\n",
    "        return\n",
    "    print(f\"üìÖ P√©riode couverte: {prophet_data['ds'].min().date()} au {prophet_data['ds'].max().date()}\")\n",
    "\n",
    "    # 5. Mod√©lisation\n",
    "    print(\"\\nü§ñ √âtape 5/5 - Mod√©lisation Prophet...\")\n",
    "    model = ProphetModel()\n",
    "    if model.train(prophet_data) and model.validate(prophet_data):\n",
    "        model.save_model()\n",
    "        print(\"\\nüéâ Pipeline ex√©cut√© avec succ√®s!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Le pipeline a rencontr√© des probl√®mes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ccce78-351a-46e3-89f5-76a34e41f869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
