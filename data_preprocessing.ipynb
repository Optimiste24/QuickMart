{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b21e8f-e27d-4cc0-9c9c-ecd1a937e6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d5c816-ce74-4b11-8038-4d1e453382e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03facff-45f8-458c-b4e2-1f87c0685353",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Prophet' object has no attribute 'stan_backend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m     79\u001b[0m     df \u001b[38;5;241m=\u001b[39m prepare_data(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarketing\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 80\u001b[0m     model, forecast, mape \u001b[38;5;241m=\u001b[39m train_and_validate(df)\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ MAPE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmape\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (objectif : < 15%)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     plot_forecast(model, forecast)\n",
      "Cell \u001b[1;32mIn[2], line 59\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     57\u001b[0m test \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m split_date]\n\u001b[0;32m     58\u001b[0m train_prophet \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m---> 59\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model()\n\u001b[0;32m     60\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_prophet)\n\u001b[0;32m     61\u001b[0m future \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmake_future_dataframe(periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test))\n",
      "Cell \u001b[1;32mIn[2], line 46\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m():\n\u001b[1;32m---> 46\u001b[0m     model \u001b[38;5;241m=\u001b[39m Prophet(weekly_seasonality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, yearly_seasonality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m                     changepoint_prior_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, seasonality_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultiplicative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     48\u001b[0m     model\u001b[38;5;241m.\u001b[39madd_regressor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m     model\u001b[38;5;241m.\u001b[39madd_regressor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpromo_active\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\prophet\\forecaster.py:155\u001b[0m, in \u001b[0;36mProphet.__init__\u001b[1;34m(self, growth, changepoints, n_changepoints, changepoint_range, yearly_seasonality, weekly_seasonality, daily_seasonality, holidays, seasonality_mode, seasonality_prior_scale, holidays_prior_scale, changepoint_prior_scale, mcmc_samples, interval_width, uncertainty_samples, stan_backend, scaling, holidays_mode)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_inputs()\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_stan_backend(stan_backend)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\prophet\\forecaster.py:168\u001b[0m, in \u001b[0;36mProphet._load_stan_backend\u001b[1;34m(self, stan_backend)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend \u001b[38;5;241m=\u001b[39m StanBackendEnum\u001b[38;5;241m.\u001b[39mget_backend_class(stan_backend)()\n\u001b[1;32m--> 168\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded stan backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39mget_type())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Prophet' object has no attribute 'stan_backend'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Chargement des données\n",
    "def load_data():\n",
    "    data_dir = Path('data')\n",
    "    try:\n",
    "        df_sales = pd.read_csv(data_dir/'ventes_enhanced.csv', parse_dates=['Date'])\n",
    "        df_weather = pd.read_csv(data_dir/'meteo_locale.csv', parse_dates=['Date'])\n",
    "        df_products = pd.read_csv(data_dir/'produits.csv')\n",
    "        df_staff = pd.read_csv(data_dir/'planning_equipes.csv', parse_dates=['Date'])\n",
    "        df_marketing = pd.read_csv(data_dir/'campagnes_marketing.csv', encoding='latin1', parse_dates=['Date_début', 'Date_fin'])\n",
    "        return {\n",
    "            'sales': df_sales,\n",
    "            'weather': df_weather,\n",
    "            'products': df_products,\n",
    "            'staff': df_staff,\n",
    "            'marketing': df_marketing\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du chargement des données: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Préparation des données\n",
    "def prepare_data(df_sales, df_weather, df_marketing):\n",
    "    df_daily = df_sales.groupby('Date').agg({'CA': 'sum', 'Magasin': 'nunique'}).reset_index()\n",
    "    df_weather_daily = df_weather.groupby('Date')['Température'].mean().reset_index()\n",
    "    df_weather_daily.rename(columns={'Température': 'temperature'}, inplace=True)\n",
    "    df_merged = pd.merge(df_daily, df_weather_daily, on='Date')\n",
    "    df_merged['promo_active'] = df_merged['Date'].apply(\n",
    "        lambda d: any((d >= row['Date_début']) & (d <= row['Date_fin']) for _, row in df_marketing.iterrows())\n",
    "    ).astype(int)\n",
    "    return df_merged\n",
    "\n",
    "# Création du modèle Prophet\n",
    "def create_model():\n",
    "    model = Prophet(weekly_seasonality=True, yearly_seasonality=False,\n",
    "                    changepoint_prior_scale=0.3, seasonality_mode='multiplicative')\n",
    "    model.add_regressor('temperature')\n",
    "    model.add_regressor('promo_active')\n",
    "    model.add_country_holidays(country_name='FR')\n",
    "    return model\n",
    "\n",
    "# Entraînement + validation + MAPE\n",
    "def train_and_validate(df):\n",
    "    split_date = df['Date'].quantile(0.8)\n",
    "    train = df[df['Date'] <= split_date]\n",
    "    test = df[df['Date'] > split_date]\n",
    "    train_prophet = train.rename(columns={'Date': 'ds', 'CA': 'y'})\n",
    "    model = create_model()\n",
    "    model.fit(train_prophet)\n",
    "    future = model.make_future_dataframe(periods=len(test))\n",
    "    future = future.merge(df[['Date', 'temperature', 'promo_active']], left_on='ds', right_on='Date', how='left')\n",
    "    forecast = model.predict(future)\n",
    "    from sklearn.metrics import mean_absolute_percentage_error\n",
    "    mape = mean_absolute_percentage_error(test['CA'], forecast.tail(len(test))['yhat'])\n",
    "    return model, forecast, mape\n",
    "\n",
    "# Affichage\n",
    "def plot_forecast(model, forecast):\n",
    "    fig1 = model.plot(forecast)\n",
    "    plt.title(\"Prévisions de chiffre d'affaires\")\n",
    "    plt.show()\n",
    "    fig2 = model.plot_components(forecast)\n",
    "    plt.show()\n",
    "\n",
    "# Exécution complète\n",
    "data = load_data()\n",
    "if data:\n",
    "    df = prepare_data(data['sales'], data['weather'], data['marketing'])\n",
    "    model, forecast, mape = train_and_validate(df)\n",
    "    print(f\"✅ MAPE: {mape:.1%} (objectif : < 15%)\")\n",
    "    plot_forecast(model, forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170001d4-2f06-4718-9826-aadeb37e3fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Local\\Temp\\ipykernel_17760\\803535250.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Local\\Temp\\ipykernel_17760\\803535250.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Optimiste\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🚀 Démarrage du pipeline de prévision\n",
      "==================================================\n",
      "\n",
      "🔍 Étape 1/5 - Chargement des données...\n",
      "\n",
      "🧹 Étape 2/5 - Nettoyage et fusion des données...\n",
      "📊 Données après nettoyage: (455, 7)\n",
      "\n",
      "⚙️ Étape 3/5 - Création des features...\n",
      "✨ Features ajoutées: 21 au total\n",
      "\n",
      "📊 Étape 4/5 - Préparation pour Prophet...\n",
      "📅 Période couverte: NaT au NaT\n",
      "\n",
      "🤖 Étape 5/5 - Modélisation Prophet...\n",
      "❌ Échec de l'entraînement: Données d'entrée invalides\n",
      "\n",
      "❌ Le pipeline a rencontré des problèmes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.serialize import model_to_json\n",
    "import holidays\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration initiale\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Chargement des données - Version améliorée\n",
    "def load_data():\n",
    "    \"\"\"Charge tous les fichiers CSV nécessaires avec gestion des erreurs\"\"\"\n",
    "    data_dir = Path('data')\n",
    "    try:\n",
    "        df_sales = pd.read_csv(data_dir/'ventes_enhanced.csv', parse_dates=['Date'])\n",
    "        df_weather = pd.read_csv(data_dir/'meteo_locale.csv', parse_dates=['Date'])\n",
    "        df_products = pd.read_csv(data_dir/'produits.csv')\n",
    "        df_staff = pd.read_csv(data_dir/'planning_equipes.csv', parse_dates=['Date'])\n",
    "        \n",
    "        return {\n",
    "            'sales': df_sales,\n",
    "            'weather': df_weather,\n",
    "            'products': df_products,\n",
    "            'staff': df_staff\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du chargement des données: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 2. Nettoyage des données - Version robuste\n",
    "def clean_data(df_sales, df_weather):\n",
    "    \"\"\"Nettoie et fusionne les données avec vérifications\"\"\"\n",
    "    try:\n",
    "        # Vérification des entrées\n",
    "        if df_sales.empty or df_weather.empty:\n",
    "            raise ValueError(\"DataFrames d'entrée vides\")\n",
    "            \n",
    "        # Gestion des outliers avec seuil dynamique\n",
    "        q_low = df_sales['CA'].quantile(0.005)\n",
    "        q_high = df_sales['CA'].quantile(0.995)\n",
    "        df_sales = df_sales[(df_sales['CA'] > q_low) & (df_sales['CA'] < q_high)]\n",
    "        \n",
    "        # Détection des jours fermés\n",
    "        daily_sales = df_sales.groupby('Date')['CA'].sum()\n",
    "        closed_days = daily_sales[daily_sales == 0].index\n",
    "        df_sales = df_sales[~df_sales['Date'].isin(closed_days)]\n",
    "        \n",
    "        # Fusion avec vérification des clés\n",
    "        df_merged = pd.merge(\n",
    "            df_sales.groupby(['Date', 'Magasin'])['CA'].sum().reset_index(),\n",
    "            df_weather,\n",
    "            left_on=['Date', 'Magasin'],\n",
    "            right_on=['Date', 'Ville'],\n",
    "            how='left'\n",
    "        ).dropna(subset=['CA'])\n",
    "        \n",
    "        # Jours fériés avec gestion des années\n",
    "        years = df_merged['Date'].dt.year.unique()\n",
    "        fr_holidays = holidays.France(years=years)\n",
    "        df_merged['is_holiday'] = df_merged['Date'].apply(lambda x: x in fr_holidays)\n",
    "        \n",
    "        return df_merged\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du nettoyage: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 3. Feature Engineering - Optimisé\n",
    "def create_features(df):\n",
    "    \"\"\"Crée des variables supplémentaires avec gestion des erreurs\"\"\"\n",
    "    try:\n",
    "        # Vérification des colonnes nécessaires\n",
    "        if 'Date' not in df.columns or 'CA' not in df.columns:\n",
    "            raise ValueError(\"Colonnes manquantes\")\n",
    "            \n",
    "        # Variables temporelles\n",
    "        df['day_of_week'] = df['Date'].dt.dayofweek\n",
    "        df['month'] = df['Date'].dt.month\n",
    "        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "        \n",
    "        # Features temporelles avancées\n",
    "        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week']/7)\n",
    "        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week']/7)\n",
    "        \n",
    "        # Lag features avec fenêtre glissante\n",
    "        for lag in [1, 7, 14]:\n",
    "            df[f'CA_lag{lag}'] = df.groupby('Magasin')['CA'].shift(lag)\n",
    "            \n",
    "        # Rolling statistics\n",
    "        for window in [7, 14, 28]:\n",
    "            df[f'CA_rolling{window}_mean'] = df.groupby('Magasin')['CA'].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).mean()\n",
    "            )\n",
    "            df[f'CA_rolling{window}_std'] = df.groupby('Magasin')['CA'].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).std()\n",
    "            )\n",
    "        \n",
    "        return df.dropna().reset_index(drop=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur dans le feature engineering: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 4. Préparation pour Prophet - Adaptatif\n",
    "def prepare_for_prophet(df, magasin_id=None):\n",
    "    \"\"\"Prépare les données pour Prophet avec sélection de magasin\"\"\"\n",
    "    try:\n",
    "        if magasin_id:\n",
    "            df = df[df['Magasin'] == magasin_id].copy()\n",
    "            \n",
    "        # Sélection des colonnes pertinentes\n",
    "        keep_cols = ['Date', 'CA', 'Température', 'is_weekend', 'is_holiday']\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        keep_cols += [col for col in numeric_cols if col not in keep_cols and 'CA_' in col]\n",
    "        \n",
    "        prophet_df = df[keep_cols].rename(columns={'Date': 'ds', 'CA': 'y'})\n",
    "        \n",
    "        # Normalisation des noms de colonnes\n",
    "        prophet_df.columns = [col.lower().replace('é', 'e') for col in prophet_df.columns]\n",
    "        \n",
    "        return prophet_df.dropna()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur de préparation Prophet: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 5. Modélisation Prophet - Version professionnelle\n",
    "class ProphetModel:\n",
    "    def __init__(self, params=None):\n",
    "        self.params = params or {\n",
    "            'daily_seasonality': False,\n",
    "            'weekly_seasonality': True,\n",
    "            'yearly_seasonality': True,\n",
    "            'changepoint_prior_scale': 0.05,\n",
    "            'seasonality_mode': 'multiplicative'\n",
    "        }\n",
    "        self.model = None\n",
    "        \n",
    "    def train(self, df):\n",
    "        \"\"\"Entraîne le modèle avec gestion complète des erreurs\"\"\"\n",
    "        try:\n",
    "            # Validation des données\n",
    "            if df is None or df.empty:\n",
    "                raise ValueError(\"Données d'entrée invalides\")\n",
    "                \n",
    "            required_cols = {'ds', 'y'}\n",
    "            if not required_cols.issubset(df.columns):\n",
    "                raise ValueError(f\"Colonnes requises manquantes: {required_cols - set(df.columns)}\")\n",
    "            \n",
    "            # Initialisation du modèle\n",
    "            self.model = Prophet(**self.params)\n",
    "            \n",
    "            # Ajout des regresseurs dynamiques\n",
    "            regressors = [col for col in df.columns if col not in required_cols]\n",
    "            for reg in regressors:\n",
    "                try:\n",
    "                    self.model.add_regressor(reg)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Regresseur {reg} ignoré: {str(e)}\")\n",
    "            \n",
    "            # Entraînement\n",
    "            self.model.fit(df)\n",
    "            print(\"✅ Modèle entraîné avec succès\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Échec de l'entraînement: {str(e)}\")\n",
    "            self.model = None\n",
    "            return False\n",
    "    \n",
    "    def validate(self, df, initial='60 days', period='15 days', horizon='30 days', mape_threshold=0.15):\n",
    "        \"\"\"Validation croisée\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"❌ Modèle non entraîné\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            df_cv = cross_validation(\n",
    "                self.model,\n",
    "                initial=initial,\n",
    "                period=period,\n",
    "                horizon=horizon\n",
    "            )\n",
    "            \n",
    "            metrics = performance_metrics(df_cv)\n",
    "            mape = metrics['mape'].mean()\n",
    "            print(f\"📊 Performance MAPE: {mape:.2%}\")\n",
    "            \n",
    "            return mape <= mape_threshold\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Échec de validation: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def save_model(self, path='models/prophet_model.json'):\n",
    "        \"\"\"Sauvegarde le modèle\"\"\"\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "            with open(path, 'w') as f:\n",
    "                f.write(model_to_json(self.model))\n",
    "            print(f\"✅ Modèle sauvegardé: {path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Échec de sauvegarde: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "# Pipeline complet avec journalisation\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"🚀 Démarrage du pipeline de prévision\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # 1. Chargement des données\n",
    "    print(\"🔍 Étape 1/5 - Chargement des données...\")\n",
    "    data = load_data()\n",
    "    if data is None:\n",
    "        return\n",
    "\n",
    "    # 2. Nettoyage et fusion\n",
    "    print(\"\\n🧹 Étape 2/5 - Nettoyage et fusion des données...\")\n",
    "    df_clean = clean_data(data['sales'], data['weather'])\n",
    "    if df_clean is None:\n",
    "        return\n",
    "    print(f\"📊 Données après nettoyage: {df_clean.shape}\")\n",
    "\n",
    "    # 3. Feature engineering\n",
    "    print(\"\\n⚙️ Étape 3/5 - Création des features...\")\n",
    "    df_features = create_features(df_clean)\n",
    "    if df_features is None:\n",
    "        return\n",
    "    print(f\"✨ Features ajoutées: {len(df_features.columns)} au total\")\n",
    "\n",
    "    # 4. Préparation Prophet\n",
    "    print(\"\\n📊 Étape 4/5 - Préparation pour Prophet...\")\n",
    "    prophet_data = prepare_for_prophet(df_features, magasin_id='Magasin_1')\n",
    "    if prophet_data is None:\n",
    "        return\n",
    "    print(f\"📅 Période couverte: {prophet_data['ds'].min().date()} au {prophet_data['ds'].max().date()}\")\n",
    "\n",
    "    # 5. Modélisation\n",
    "    print(\"\\n🤖 Étape 5/5 - Modélisation Prophet...\")\n",
    "    model = ProphetModel()\n",
    "    if model.train(prophet_data) and model.validate(prophet_data):\n",
    "        model.save_model()\n",
    "        print(\"\\n🎉 Pipeline exécuté avec succès!\")\n",
    "    else:\n",
    "        print(\"\\n❌ Le pipeline a rencontré des problèmes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ccce78-351a-46e3-89f5-76a34e41f869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
