### **Plan d'Exécution Détaillé – Mission QuickMart**  
**Objectif** : Démarrer immédiatement le travail avec une approche structurée et des livrables intermédiaires clairs.  

---

## **📅 Jour 1-2 : Setup & Exploration des Données**  
### **1. Environnement Technique**  
- **Créer un dossier projet** :  
  ```bash
  mkdir quickmart_analysis && cd quickmart_analysis
  ```
- **Initialiser un environnement Python** (conda ou venv) :  
  ```bash
  conda create -n quickmart python=3.9 && conda activate quickmart
  pip install pandas numpy matplotlib seaborn prophet scikit-learn streamlit
  ```
- **Structurer les fichiers** :  
  ```
  /data  
    ├── ventes.csv  
    ├── stocks.csv  
    ├── plannings.csv  
    └── meteo_campaigns.csv  
  /notebooks  
    ├── 01_data_cleaning.ipynb  
    └── 02_eda.ipynb  
  /scripts  
    ├── forecast_model.py  
    └── dashboard.py  
  ```

### **2. Analyse Exploratoire (EDA)**  
**Actions clés** :  
- Charger chaque CSV dans Pandas et vérifier :  
  ```python
  import pandas as pd
  df_ventes = pd.read_csv('data/ventes.csv')
  print(df_ventes.isnull().sum())  # Trouver les valeurs manquantes
  df_ventes['date'] = pd.to_datetime(df_ventes['date'])  # Standardiser les dates
  ```
- **Visualisations rapides** (via Seaborn) :  
  - Distribution du CA par magasin (boxplot)  
  - Corrélation entre ventes et température/météo  
  - Saisonnalité hebdomadaire (groupby jour de la semaine)  

**Livrable intermédiaire** :  
➡ **Rapport EDA (1 page)** : Principales anomalies (ex. ruptures récurrentes) et 3 opportunités d'optimisation identifiées.  

---

## **📈 Jours 3-5 : Préprocessing & Modèle Prophet**  
### **1. Nettoyage des Données**  
- **Gérer les outliers** :  
  ```python
  df_ventes = df_ventes[(df_ventes['montant'] > 0) & (df_ventes['montant'] < df_ventes['montant'].quantile(0.99)]
  ```
- **Fusionner les données** :  
  ```python
  df_merged = pd.merge(df_ventes, df_meteo, on=['magasin_id', 'date'])
  ```

### **2. Entraînement du Modèle**  
**Script `forecast_model.py`** :  
```python
from prophet import Prophet

model = Prophet(weekly_seasonality=True, yearly_seasonality=False)
model.add_regressor('temperature')  # Ajouter la météo comme variable externe
model.fit(df_merged[['date', 'montant', 'temperature']])

# Prévisions 30 jours
future = model.make_future_dataframe(periods=30)
future = future.merge(df_meteo[['date', 'temperature']], on='date')
forecast = model.predict(future)
```

**Validation** :  
- Backtesting sur les 3 derniers mois (MAPE < 15% cible).  
- Exporter les prévisions en CSV pour le dashboard.  

**Livrable intermédiaire** :  
➡ **Fichier `predictions.csv`** + graphique interactif (Plotly) dans un notebook.  

---

## **🖥️ Jours 6-10 : Dashboard Streamlit (MVP)**  
### **1. Architecture du Dashboard**  
**Fichier `dashboard.py`** :  
```python
import streamlit as st

st.title("QuickMart Analytics")
tab1, tab2, tab3 = st.tabs(["Ventes", "Stocks", "RH"])

with tab1:
  st.line_chart(df_ventes.groupby('date')['montant'].sum())
  st.map(df_magasins)  # Cartographie des performances
```

### **2. Fonctionnalités Clés**  
- **Filtres** : Sélection par magasin, période, catégorie.  
- **Alertes** : Ruptures de stock en temps réel (via jointure avec `stocks.csv`).  
- **Export** : Bouton pour télécharger les données filtrées.  

**Test** :  
```bash
streamlit run dashboard.py
```

**Livrable intermédiaire** :  
➡ **Lien localhost** à partager pour feedback (ex: `http://localhost:8501`).  

---

## **🔍 Jours 11-15 : Analyse Approfondie & Recommandations**  
### **1. Clustering des Magasins**  
- Utiliser KMeans sur :  
  - CA/m²  
  - Taux de rotation des stocks  
  - Nombre de transactions/jour  

### **2. Pricing Dynamique**  
- Identifier les produits à élasticité-prix (régressions linéaires par produit).  

### **3. Optimisation des Plannings**  
- Croiser :  
  - Pics de ventes prédits  
  - Données de productivité/heure  

**Livrable intermédiaire** :  
➡ **Présentation PPT (5 slides)** : 3 recommandations prioritaires avec gains estimés.  

---

## **✅ Jours 16-20 : Finalisation & Transfert**  
1. **Documentation** :  
   - README.md avec instructions pour lancer le modèle/dashboard.  
2. **Session de transfert** :  
   - 1h de démo + 30 min de Q&A.  
3. **Support post-projet** :  
   - 2 ajustements gratuits sous 15 jours.  

---

### **📌 Checklist de Démarrage Immédiat**  
1. [ ] Vérifier l'accès à tous les fichiers CSV.  
2. [ ] Lancer l’EDA dans `notebooks/01_data_cleaning.ipynb`.  
3. [ ] Envoyer un email au client pour confirmer le début des travaux.  

**Exemple d’email** :  
```  
Objet : QuickMart - Lancement des travaux [18/04]  

Bonjour [Prénom],  

Je confirme le démarrage de la mission aujourd'hui. Voici le plan des 5 prochains jours :  
- J1-2 : Audit des données & EDA → Rapport vendredi 19/04 AM  
- J3-5 : 1ère version du modèle de prévision → Partage des premiers résultats lundi 22/04  

Je reste disponible pour tout ajustement.  

Bien cordialement,  
Yassh  
```  

--- 

**Points Clés à Surveiller** :  
⚠ **Risque #1** : Données manquantes dans les plannings → Contingence : Imputation par moyenne mobile.  
⚠ **Risque #2** : Modèle trop lent sur 25 magasins → Solution : Parallélisation avec Dask.  

Ajustez ce plan en fonction de vos premiers findings !